
# 1.0 Introduction

"The true challenge to artificial intelligence proved to be solving the tasks that are easy for people to perform but are hard for people to describe formally - problems that we solve intuitively, that feel automatic, like recognizing spoken words or faces in images."

This book describes solutions to these intuitive problems. These solutions teach computers about hierarchies of concepts through experience or example.  More complex concepts are described in terms of simpler concepts in layers.  The multitude layers gives rise to the name deep learning.

"One of the key challenges in AI is how to get this informal knowledge [about the world] into a computer."

The **knowledge base** approach to AI involves hard-coding knowledge (or logical rules) in formal languages - this clearly becomes unwieldly.

**Machine learning** is the next step where computers learn these rules from data.

"The performance of thse simple machine learning algorithms [such as logistic regression and naive Bayes] depends heavily on the **representation** of the data they are given... Each piece of information included in the representation... is known as a **feature**."

"This dependence on representations is a general phenomenon that appears throughout computer science and even daily life. In computer science, operations such as searching a collection of data can proceed exponentially faster if the collection is structured and indexed intelligently. People can easily perform arithmetic on Arabic numerals but ﬁnd arithmetic on Roman numerals much more time consuming. It is not surprising that the choice of representation has an enormous effect on the performance of machine learning algorithms."

"Many artiﬁcial intelligence tasks can be solved by designing the right set of features to extract for that task, then providing these features to a simple machine learning algorithm."

"One solution to this problem is to use machine learning to discover not only the mapping from representation to output but also the representation itself.  This approach is known as **representation learning**. Learned representations often result in much better performance than can be obtained with hand-designed representations."

## 1.1 Who Should Read This Book?

Either (under)graduate students learning ML or software engineers who want to learn machine learning.

## 1.2 Historical Trends in Deep Learning

* Deep learning has had a long and rich history, but has gone by many names, reﬂecting different philosophical viewpoints, and  has waxed and waned in popularity.

* Deep learning has become more useful as the amount of available training data has increased.

* Deep learning models have grown in size over time as computer infrastructure (both hardware and software) for deep learning has improved.

* Deep learning has solved increasingly complicated applications with increasing accuracy over time.

### 1.2.1 The Many Names and Changing Fortunes of Neural Networks

Deep learning is an old field that only appears new because of previous unpopularity and changing names.

1. Cybernetics: 1940-1960

2. Connectionism: 1980-1990

3. Deep Learning: 2006-Present

Artifical Neural Networks (ANN) represent the biologically-based history of the alogrithms.  ANNs were originally models designed to understand the workings of the brain, now new findings in biology are translated to ANNs.
